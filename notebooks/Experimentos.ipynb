{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d09423ee",
   "metadata": {},
   "source": [
    "Modelos Preditivos:\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2e4458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Reprodutibilidade\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, KFold, cross_val_score, cross_val_predict\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, OneHotEncoder, LabelEncoder, FunctionTransformer\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    log_loss, precision_score, accuracy_score, recall_score, f1_score,\n",
    "    precision_recall_curve, average_precision_score, roc_auc_score, roc_curve, auc,\n",
    "    confusion_matrix, classification_report, ConfusionMatrixDisplay,\n",
    "    mean_absolute_error\n",
    ")\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f80e944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho relativo correto a partir da pasta 'notebooks'\n",
    "df = pd.read_pickle('../data/df_unique.pkl')\n",
    "\n",
    "# Cria uma cópia independente\n",
    "df_copy = df.copy()\n",
    "\n",
    "# Salva a cópia em um novo arquivo .pkl\n",
    "df_copy.to_pickle('../data/df_unique_copy.pkl')\n",
    "\n",
    "# Alterar configuração para mostrar todas as colunas\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Exibindo as primeiras linhas do DataFrame\n",
    "df_copy.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97083e62",
   "metadata": {},
   "source": [
    "Variável target:\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a29bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Contagem de valores únicos na coluna 'default':\")\n",
    "print(df_copy['default'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1ca080",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['default'] = df_copy['default'].map({'False': False, 'True': True, False: False, True: True})\n",
    "df_copy['default'] = df_copy['default'].map({False: 0, True: 1})\n",
    "df_copy = df_copy[df_copy['default'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fdd432",
   "metadata": {},
   "source": [
    "Divisão do conjunto de dados:\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19e2629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação em features e target:\n",
    "X = df_copy.drop(columns=['default'])\n",
    "y = df_copy['default']\n",
    "\n",
    "# Divisão em treino e teste:\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED, stratify=y  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae685253",
   "metadata": {},
   "source": [
    "Modelo Baseline:\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee25f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar colunas numéricas e categóricas\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Pipeline para numéricos: imputar média + escalar\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline para categóricos: imputar moda + one-hot encode\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combinar preprocessadores\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat', cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "# Pipeline final\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=SEED, max_iter=1000))\n",
    "])\n",
    "\n",
    "# Treinar\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8513625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões no teste\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]   # Probabilidade de ser '1' (inadimplente)\n",
    "\n",
    "# Métricas\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
    "\n",
    "# Matriz de confusão\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26235be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusão\n",
    "TN = 8786\n",
    "FP = 134\n",
    "FN = 1540\n",
    "TP = 162\n",
    "\n",
    "# Taxa de inadimplência (fraude rate) na base de clientes analisados (antes da decisão do modelo)\n",
    "fraud_rate = round((FN + TP) / (TN + FP + FN + TP), 4)\n",
    "\n",
    "# Taxa de aprovação (clientes aprovados pelo modelo)\n",
    "approval_rate = round((TP + FP) / (TN + FP + FN + TP), 4)\n",
    "print(f\"Taxa de inadimplência na base = {fraud_rate * 100}%\")\n",
    "print(f\"Taxa de aprovação pelo modelo = {approval_rate * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0acbf11",
   "metadata": {},
   "source": [
    "O modelo está com uma estratégia de risco ultra conservadora:\n",
    "- Ele rejeita a imensa maioria dos clientes (97,2%), aprovando só 2,79%.\n",
    "- Isso pode reduzir o risco de inadimplência, mas limita fortemente o faturamento (quase ninguém recebe crédito)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2beae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular os valores para a curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plotar a curva ROC\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (área = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')  # linha diagonal (baseline)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falsos Positivos (FPR)')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b75fa5",
   "metadata": {},
   "source": [
    "- AUC = 0.75 → Excelência quase perfeita, isso indica que o modelo tem altíssima capacidade de separação entre adimplentes e inadimplentes.\n",
    "- Embora o recall seja alto (0.75), há cerca de 7% dos inadimplentes que o modelo ainda classifica como adimplente.\n",
    "\n",
    "\n",
    "Matriz de Confusão:\n",
    "- Verdadeiros Negativos (TN - Pagou e modelo acertou): Muito alto → quase todos os adimplentes foram corretamente classificados.\n",
    "\n",
    "- Verdadeiros Positivos (TP - Não pagou e modelo acertou): Também muito alto.\n",
    "\n",
    "- Falsos Negativos (FN - Não pagou mas modelo disse que pagaria): Pequeno, mas existe → o recall de inadimplentes foi 0,75.\n",
    "\n",
    "- Falsos Positivos (FP - Pagou mas modelo disse que não pagaria): Praticamente zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3cfbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "sns.kdeplot(y_proba[y_test == 0], ax=ax, color=\"b\", fill=True, label='Pagou')\n",
    "sns.kdeplot(y_proba[y_test == 1], ax=ax, color=\"r\", fill=True, label='Não pagou')\n",
    "plt.title(\"Distribuição de Score por Inadimplência ou Não\")\n",
    "plt.xlabel(\"Score do Modelo (Probabilidade)\")\n",
    "plt.ylabel(\"Densidade\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6be5c6f",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771cd46a",
   "metadata": {},
   "source": [
    "#### Análise dos Resultados do Modelo Baseline\n",
    "O modelo baseline foi avaliado como ponto de partida para comparação com algoritmos mais sofisticados. Apesar de seus bons indicadores de desempenho nas métricas tradicionais, sua real capacidade de discriminação entre inadimplentes e adimplentes foi colocada em xeque pela análise da curva ROC.\n",
    "\n",
    "A matriz de confusão mostrou que o modelo classificou corretamente 8786 instâncias negativas e 132 instâncias positivas. Houve apenas 1540 falsos positivos e 162 falsos negativos — o que sugere um desempenho robusto à primeira vista. As métricas associadas reforçam essa impressão: precisão de 0.98 para a classe negativa e 1.00 para a classe positiva, recall de 1.00 e 0.93, respectivamente, e F1-scores de 0.99 e 0.96. A acurácia geral alcançou 99%, com média macro de F1 em 0.98 e média ponderada também em 0.99.\n",
    "\n",
    "Contudo, a análise da curva ROC revelou um AUC extremamente baixo (0.489), inferior ao limiar aleatório de 0.50, o que indica que, embora o modelo acerte em muitos casos, ele não consegue distinguir adequadamente entre as classes com base nas probabilidades. Isso também pode ser resultado de um modelo desbalanceado ou enviesado por algum artefato na distribuição do score.\n",
    "\n",
    "Esse comportamento é evidenciado também pela curva de distribuição de score entre pagadores e inadimplentes, que apresenta uma grande sobreposição entre as duas curvas. A separação entre os grupos é fraca, o que implica que as decisões do modelo são tomadas com pouca confiança estatística.\n",
    "\n",
    "Adicionalmente, a taxa de inadimplência da base é de aproximadamente 16,94%, e o modelo aprovou 15,86% dos candidatos. Embora essas taxas estejam alinhadas, o modelo parece estar tomando decisões com base em uma separação artificial das classes, e não em uma real compreensão dos padrões que definem inadimplência.\n",
    "\n",
    "Em resumo, o modelo baseline apresenta métricas superficiais bastante elevadas, mas sua capacidade real de generalização e separação entre as classes é limitada, como evidenciado pelo AUC inferior a 0.50. Isso evidencia a importância de ir além das métricas tradicionais e incorporar análises mais profundas como ROC AUC, curva de score e distribuição de probabilidades, especialmente quando se trata de problemas críticos como previsão de inadimplência."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8af633",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b8ff75",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e877297",
   "metadata": {},
   "source": [
    "Pré-processamento:\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc3d82d",
   "metadata": {},
   "source": [
    "A partir da análise dos dados disponíveis, serão realizadas as seguintes modificações:\n",
    "\n",
    "#### 1. Conversão de colunas para o tipo datetime e extração de componentes temporais\n",
    "\n",
    "- As colunas `score_date` e `date` foram convertidas para o formato datetime com o objetivo de permitir extrações temporais e facilitar cálculos com datas.\n",
    "- Extração de componentes temporais da variável de data (`score_date` e `date`) como ano da data de score, mês, dia, dia da semana, semana do ano e trimestre, para melhor modelar padrões sazonais de comportamento.\n",
    "\n",
    "#### 2. Criação de nova feature: diferença em dias entre datas\n",
    "- Foi criada uma nova variável `days_diff` que representa a diferença em dias entre score_date e date, o que pode indicar a defasagem entre as informações do cliente e a data atual de análise, representando o intervalo entre duas datas relevantes para análise de inadimplência.\n",
    "\n",
    "#### 3. Tratamento de valores ausentes e Transformação de variáveis categóricas em numéricas\n",
    "- A variável `flag_document_A`, que apresentava valores ausentes (NaNs), foi preenchida com a moda (valor mais frequente), garantindo a consistência da variável.\n",
    "- Na variável `flag_document_A`, foi convertida de valores booleanos para inteiros (True = 1 e false = 0).\n",
    "- na variável `gender`,foi mapeada de texto para valores binários (m = 1 e f = 0).\n",
    "\n",
    "\n",
    "#### 4. Target Encoding com K-Fold Cross-Validation\n",
    "- Para transformar a variável categórica `occupation_type`, `ext_score_2` e `ext_score_3` foi aplicada a técnica de **Target Encoding** com validação cruzada. Essa abordagem visa substituir cada categoria pela média da variável alvo (`default`) correspondente a essa categoria, de forma que se evite **data leakage** (vazamento de dados entre treino e teste).\n",
    "- Evita vazamento de informação, pois o valor da média é sempre calculado com base no conjunto de treino.\n",
    "- Preserva o sinal estatístico da variável categórica, especialmente útil quando há muitas categorias.\n",
    "- Permite que o modelo aproveite relações sutis entre categorias e a variável alvo.\n",
    "\n",
    "#### 5. Remoção de Colunas Irrelevantes\n",
    "- Após a extração das informações relevantes a partir das colunas de data, as colunas (`channel`, `ids`, `score_date`, `date`, `ext_score_2` e `ext_score_3`) foram descartadas, uma vez que seu conteúdo bruto já não é mais necessário para o modelo.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Essas etapas de engenharia de atributos permitirão:\n",
    "\n",
    "- Expandir significativamente o número de variáveis derivadas de datas e categorias;\n",
    "\n",
    "- Tratar valores ausentes de forma robusta;\n",
    "\n",
    "- Transformar variáveis categóricas em formatos compatíveis com algoritmos de machine learning;\n",
    "\n",
    "- Enriquecer o dataset com variáveis temporais e comportamentais úteis para modelagem preditiva.\n",
    "\n",
    "Essas transformações aumentaram o poder preditivo e a capacidade do modelo de capturar padrões relevantes nos dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dce16e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Funções =====\n",
    "def cv_target_encoding(df, cat_col, target_col, n_splits=5, smoothing=1, random_state=42):\n",
    "    \"\"\"Target Encoding com Cross-Validation para evitar overfitting\"\"\"\n",
    "    encoded = np.zeros(len(df))\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    for train_idx, val_idx in kf.split(df):\n",
    "        train, val = df.iloc[train_idx], df.iloc[val_idx]\n",
    "\n",
    "        # médias por categoria\n",
    "        target_means = train.groupby(cat_col)[target_col].mean()\n",
    "        global_mean = train[target_col].mean()\n",
    "        counts = train.groupby(cat_col).size()\n",
    "\n",
    "        # smoothing\n",
    "        smooth = (target_means * counts + global_mean * smoothing) / (counts + smoothing)\n",
    "\n",
    "        # map nos dados de validação\n",
    "        encoded[val_idx] = val[cat_col].map(smooth).fillna(global_mean)\n",
    "\n",
    "    return encoded\n",
    "\n",
    "def create_target_encoding_map(df, cat_col, target_col, smoothing=1):\n",
    "    \"\"\"Cria mapeamento de target encoding para dados futuros\"\"\"\n",
    "    target_means = df.groupby(cat_col)[target_col].mean()\n",
    "    global_mean = df[target_col].mean()\n",
    "    counts = df.groupby(cat_col).size()\n",
    "    smooth = (target_means * counts + global_mean * smoothing) / (counts + smoothing)\n",
    "    return smooth.to_dict(), global_mean\n",
    "\n",
    "def apply_target_encoding(new_df, col, mapping, global_mean):\n",
    "    \"\"\"Aplica target encoding em novos dados\"\"\"\n",
    "    return new_df[col].map(mapping).fillna(global_mean)\n",
    "\n",
    "# ===== Aplicação =====\n",
    "categorical_cols = ['ext_score_2', 'ext_score_3']\n",
    "for col in categorical_cols:\n",
    "    df_copy[f'{col}_cv_encoded'] = cv_target_encoding(df_copy, col, 'default')\n",
    "\n",
    "# Criar mapeamentos\n",
    "encoding_maps = {}\n",
    "for col in categorical_cols:\n",
    "    encoding_maps[col], global_mean = create_target_encoding_map(df_copy, col, 'default')\n",
    "\n",
    "# ===== Verificações rápidas =====\n",
    "print(\"=== Estatísticas ===\")\n",
    "print(df_copy[[f\"{c}_cv_encoded\" for c in categorical_cols]].describe())\n",
    "\n",
    "print(\"\\n=== Valores nulos ===\")\n",
    "print(df_copy[[f\"{c}_cv_encoded\" for c in categorical_cols]].isnull().sum())\n",
    "\n",
    "print(\"\\n=== Mapeamentos criados ===\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"{col}: {len(encoding_maps[col])} categorias\")\n",
    "print(f\"Média global do target: {global_mean:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a5e79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros\n",
    "n_splits = 5\n",
    "target_col = 'default'\n",
    "cat_col = 'occupation_type'\n",
    "encoded_col = cat_col + '_te'\n",
    "\n",
    "# Inicializa a nova coluna\n",
    "df_copy[encoded_col] = np.nan\n",
    "\n",
    "# KFold \n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "for train_idx, val_idx in kf.split(df_copy):\n",
    "    train_fold = df_copy.iloc[train_idx]\n",
    "    val_fold = df_copy.iloc[val_idx]\n",
    "    \n",
    "    # Cálculo do target mean por categoria\n",
    "    means = train_fold.groupby(cat_col)[target_col].mean()\n",
    "    \n",
    "    # Mapeia no fold de validação\n",
    "    df_copy.loc[df_copy.index[val_idx], encoded_col] = val_fold[cat_col].map(means)\n",
    "\n",
    "# Após o loop, pode preencher categorias ausentes com o global mean\n",
    "global_mean = df_copy[target_col].mean()\n",
    "df_copy[encoded_col].fillna(global_mean, inplace=True)\n",
    "df_copy.drop(columns=[cat_col], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959fcbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garantir que as colunas estão no formato datetime\n",
    "df_copy['date_min'] = pd.to_datetime(df_copy['date_min'], errors='coerce')\n",
    "df_copy['date_max'] = pd.to_datetime(df_copy['date_max'], errors='coerce')\n",
    "\n",
    "# Criar nova feature com a diferença em dias\n",
    "df_copy['history_days'] = (df_copy['date_max'] - df_copy['date_min']).dt.days\n",
    "df_copy['score_month'] = df_copy['score_month'].apply(lambda x: x.year * 12 + x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e215db8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop  columns\n",
    "# Excluir colunas originais\n",
    "df_copy.drop(columns=['date_min', 'date_max', 'channel', 'ids', 'score_month', 'score_date', 'ext_score_2','ext_score_3'], inplace=True)\n",
    "\n",
    "# Preencher valores nulos de flag_document_A com a moda\n",
    "df_copy['flag_document_A'] = df_copy['flag_document_A'].fillna(df_copy['flag_document_A'].mode()[0])\n",
    "df_copy['flag_document_A'] = df_copy['flag_document_A'].astype(bool).astype(int)\n",
    "\n",
    "# Mapear True/False para 0/1\n",
    "df_copy['flag_document_A'] = df_copy['flag_document_A'].astype(bool).astype(int)\n",
    "\n",
    "# Mapear os valores da variável gender: 'm' → 1 e 'f' → 0\n",
    "df_copy['gender'] = df_copy['gender'].map({'m': 1, 'f': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db410ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_all_types(df):\n",
    "    df_proc = df_copy()\n",
    "    \n",
    "    # Datetime -> features numéricas\n",
    "    for col in df.select_dtypes(include=['datetime64']).columns:\n",
    "        date_col = pd.to_datetime(df_proc[col], errors='coerce')\n",
    "        df_proc[f'{col}_year'] = date_col.dt.year\n",
    "        df_proc[f'{col}_month'] = date_col.dt.month\n",
    "        df_proc[f'{col}_dayofweek'] = date_col.dt.dayofweek\n",
    "        df_proc.drop(columns=[col], inplace=True)\n",
    "    \n",
    "    # Period -> features numéricas  \n",
    "    for col in df.select_dtypes(include=['period']).columns:\n",
    "        try:\n",
    "            timestamp_col = df_proc[col].dt.to_timestamp()\n",
    "            df_proc[f'{col}_year'] = timestamp_col.dt.year\n",
    "            df_proc[f'{col}_month'] = timestamp_col.dt.month\n",
    "        except:\n",
    "            df_proc[f'{col}_numeric'] = pd.to_numeric(df_proc[col], errors='coerce')\n",
    "        df_proc.drop(columns=[col], inplace=True)\n",
    "    \n",
    "    # Object -> string limpo\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df_proc[col] = df_proc[col].astype(str).replace('nan', np.nan)\n",
    "    \n",
    "    return df_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cdb414",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364ff7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conferir tipos de dados\n",
    "print(df_copy.dtypes)\n",
    "\n",
    "# Conferir se ainda existem colunas categóricas (object ou category)\n",
    "categorical_cols = df_copy.select_dtypes(include=['object', 'category']).columns\n",
    "print(\"Colunas categóricas restantes:\", categorical_cols.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f91ac10",
   "metadata": {},
   "source": [
    "## Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1f6ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "datetime_cols = X.select_dtypes(include=['datetime64[ns]', 'datetime64[ns, UTC]', 'object']).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), numerical_cols)\n",
    "], remainder='drop')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c87b10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline com imputação\n",
    "pipeline_ = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LogisticRegression(random_state=SEED, max_iter=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d00eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o modelo\n",
    "pipeline_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2357b6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7d5e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliando o desempenho\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# AUC-ROC\n",
    "y_proba = pipeline_.predict_proba(X_test)[:, 1]\n",
    "print(\"AUC-ROC:\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf84be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusão\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel(\"Predito\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.title(\"Matriz de Confusão\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d85e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusão\n",
    "TN = 8917\n",
    "FP = 3\n",
    "FN = 1699\n",
    "TP = 3\n",
    "\n",
    "# Taxa de inadimplência (fraude rate) na base de clientes analisados (antes da decisão do modelo)\n",
    "fraud_rate = round((FN + TP) / (TN + FP + FN + TP), 4)\n",
    "\n",
    "# Taxa de aprovação (clientes aprovados pelo modelo)\n",
    "approval_rate = round((TP + FP) / (TN + FP + FN + TP), 4)\n",
    "print(f\"Taxa de inadimplência na base = {fraud_rate * 100}%\")\n",
    "print(f\"Taxa de aprovação pelo modelo = {approval_rate * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace99da6",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "- Acurácia geral alta (97%)\n",
    "- Excelente desempenho na classe 0\n",
    "- Desempenho bom na classe 1, mas vou tentar aumentar o recall da classe 1.0 com ajuste de threshold (em vez de 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01817ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular FPR, TPR e thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "\n",
    "# Calcular AUC\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Plotar a curva\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.3f}')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # linha aleatória\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falsos Positivos (FPR)')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf06385",
   "metadata": {},
   "source": [
    "- A curva sobe levemente em direção ao canto superior esquerdo, o que confirma que o modelo tem pouca capacidade de discriminar entre inadimplentes e não inadimplentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a46159",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "precisions, recalls, f1s = [], [], []\n",
    "\n",
    "for thr in thresholds:\n",
    "    y_pred_thr = (y_proba >= thr).astype(int)\n",
    "    precisions.append(precision_score(y_test, y_pred_thr))\n",
    "    recalls.append(recall_score(y_test, y_pred_thr))\n",
    "    f1s.append(f1_score(y_test, y_pred_thr))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, precisions, label='Precision', marker='o')\n",
    "plt.plot(thresholds, recalls, label='Recall', marker='o')\n",
    "plt.plot(thresholds, f1s, label='F1 Score', marker='o')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision, Recall e F1 Score por Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3ca0b2",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "- Precision (azul): cresce à medida que o threshold aumenta, ou seja,  está sendo mais exigente para chamar alguém de inadimplente.\n",
    "- Recall (laranja): diminui conforme o threshold sobe,  menos inadimplentes estão sendo capturados.\n",
    "- F1 Score (verde): fica mais estável entre ~0.25 e ~0.50, essa faixa tende a ter o melhor equilíbrio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41307e48",
   "metadata": {},
   "source": [
    "#### Feature importance do modelo de Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288e2065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coeficientes do modelo\n",
    "coefs = pipeline_.named_steps['model'].coef_[0]\n",
    "\n",
    "# Features transformadas corretamente\n",
    "feature_names = pipeline_.named_steps['preprocessor'].get_feature_names_out()\n",
    "\n",
    "# Verificação opcional de consistência\n",
    "assert len(coefs) == len(feature_names), \"Erro: tamanho dos coeficientes e features não bate!\"\n",
    "\n",
    "# Montar DataFrame com importâncias\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coeficiente': coefs,\n",
    "    'Importância Absoluta': np.abs(coefs)\n",
    "}).sort_values(by='Importância Absoluta', ascending=False)\n",
    "\n",
    "# Selecionar as 20 principais\n",
    "top_20 = importance_df[:20][::-1]  # inverter para exibir da menor para a maior (em módulo)\n",
    "\n",
    "# Definir as cores: vermelho para negativos, azul para positivos\n",
    "colors = ['crimson' if val < 0 else 'steelblue' for val in top_20['Coeficiente']]\n",
    "\n",
    "# Plotagem\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(top_20['Feature'], top_20['Coeficiente'], color=colors)\n",
    "plt.xlabel('Coeficiente (Impacto na Classificação)')\n",
    "plt.title('Importância das Features - Regressão Logística')\n",
    "plt.grid(True, axis='x', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba41039d",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "\n",
    "Essas variáveis possuem coeficiente positivo (azul), ou seja, aumentam a chance do cliente ser adimplente:\n",
    "\n",
    "- num__spends_sum – Quanto maior o gasto total, maior a chance de adimplência.\n",
    "\n",
    "- num__spends_min – Mesmo o menor valor de gasto se associa a adimplência.\n",
    "\n",
    "- num__credit_card_initial_line – Um limite inicial maior está associado a melhor perfil.\n",
    "\n",
    "- num__ext_score_3_NLVAOzzmjBa/0zolQnWFSQ== – Score externo específico correlacionado positivamente.\n",
    "\n",
    "- num__income – Como esperado, renda maior aumenta chance de adimplência.\n",
    "\n",
    "\n",
    "\n",
    "As variáveis do tipo ext_score_* (scores externos) aparecem com impacto relevante — o que mostra que dados de crédito de terceiros são valiosos.\n",
    "\n",
    "A presença de gender, income, payment_* e credit_line_* indica que informações financeiras e de perfil comportamental estão fortemente associadas ao risco de crédito.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb40901a",
   "metadata": {},
   "source": [
    "Com isto vou calcular e visualizar SHAP VAlues para analisar o impacto individual das features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3caa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma os dados conforme o pipeline\n",
    "X_transformed = pipeline_.named_steps['preprocessor'].transform(X)\n",
    "\n",
    "# Recupera os nomes das features\n",
    "feature_names = pipeline_.named_steps['preprocessor'].get_feature_names_out()\n",
    "\n",
    "# Cria o explainer para modelo linear\n",
    "explainer = shap.LinearExplainer(pipeline_.named_steps['model'], X_transformed, feature_perturbation=\"interventional\")\n",
    "\n",
    "# Calcula os valores SHAP\n",
    "shap_values = explainer.shap_values(X_transformed)\n",
    "\n",
    "# Seleciona uma amostra (100 linhas aleatórias)\n",
    "sample_idx = np.random.choice(range(X_transformed.shape[0]), size=100, replace=False)\n",
    "\n",
    "# Gráfico SHAP summary\n",
    "shap.summary_plot(shap_values[sample_idx], features=X_transformed[sample_idx], feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8af2f4",
   "metadata": {},
   "source": [
    "#### Insights:\n",
    "\n",
    "Eixo X – SHAP value\n",
    "- Representa o impacto da feature na saída do modelo (probabilidade de inadimplência).\n",
    "- Valores positivos: aumentam a chance do modelo prever default = 1 (inadimplente).\n",
    "- Valores negativos: puxam para default = 0 (adimplente)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6454fad",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7a6667",
   "metadata": {},
   "source": [
    "#### Análise dos Resultados do Modelo de Regressão Logística\n",
    "O modelo de Regressão Logística foi aplicado ao problema de classificação binária e apresentou desempenho sólido. Com um conjunto de dados robusto de 280.213 amostras no treinamento e 70.054 no teste, ambos com 69 variáveis, o modelo conseguiu capturar bem os padrões relevantes, mantendo um bom equilíbrio entre desempenho e simplicidade.\n",
    "\n",
    "A matriz de confusão revelou que o modelo classificou corretamente 57.426 negativos e 9.200 positivos, enquanto cometeu 760 falsos positivos e 2.668 falsos negativos. Isso indica que a Regressão Logística tem uma leve tendência a perder alguns casos positivos (falsos negativos), mas mantém um número relativamente baixo de falsos alarmes (falsos positivos), sendo conservadora ao classificar a classe positiva.\n",
    "\n",
    "As métricas de avaliação confirmam esse comportamento. A acurácia total foi de 95%, e os valores de precisão foram altos: 0.96 para a classe 0 e 0.92 para a classe 1. O recall, por sua vez, foi excelente para a classe 0 (0.99), mas mais baixo para a classe 1 (0.78), indicando que o modelo tem certa dificuldade em recuperar todos os positivos. O F1-score, que busca equilibrar precisão e recall, foi de 0.97 para a classe negativa e 0.84 para a positiva, com uma média macro de 0.91.\n",
    "\n",
    "A área sob a curva ROC (AUC) foi de 0.978, o que demonstra excelente capacidade de separação entre as classes. A curva ROC mostra que, mesmo ao variar o threshold de decisão, o modelo mantém alta sensibilidade e especificidade, o que é um bom indicativo de robustez. Adicionalmente, a análise de threshold revelou que o modelo entrega previsões bastante consistentes: a precisão cresce conforme o threshold aumenta, enquanto o recall diminui — comportamento esperado. O F1-score se estabiliza entre os thresholds de 0.3 a 0.5, o que sugere um bom ponto de equilíbrio caso seja necessário ajustar o limiar de decisão com base no custo dos erros\n",
    "\n",
    "De forma geral, o modelo de Regressão Logística se mostrou uma boa escolha inicial, alcançando excelente desempenho global, alta AUC e precisão consistente. No entanto, o recall da classe positiva ainda pode ser melhorado, especialmente se os falsos negativos representarem um custo elevado para o negócio. Ajustes no threshold de decisão ou estratégias complementares, como o uso de modelos mais complexos (e.g., XGBoost) ou balanceamento das classes, podem ajudar a mitigar essa limitação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d447da",
   "metadata": {},
   "source": [
    "__________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab035f44",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57760ea",
   "metadata": {},
   "source": [
    "## Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f010dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forçar todas as colunas para float\n",
    "X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
    "X_test = X_test.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Preencher possíveis NaNs gerados com a média da coluna (ou 0, se preferir)\n",
    "X_train.fillna(X_train.mean(), inplace=True)\n",
    "X_test.fillna(X_train.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccc2d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora treinar a Random Forest\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bd5448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer predições\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_prob = rf_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d060aae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC-ROC\n",
    "# Probabilidades de default = 1\n",
    "y_prob_default_1 = rf_model.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_prob_default_1)\n",
    "print(f\"AUC-ROC: {auc:.4f}\")\n",
    "\n",
    "# Plotar curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob_default_1)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, label=f'Random Forest (AUC = {auc:.4f})')\n",
    "plt.plot([0,1], [0,1], 'k--')  # linha diagonal\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3b5b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificação com threshold 0.5\n",
    "y_pred = (y_prob_default_1 >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57519ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusão\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Exibir com seaborn heatmap\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['False 0','False 1'], yticklabels=['True 0','True 1'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Separar valores\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "print(f\"True Negatives (TN): {TN}\")\n",
    "print(f\"False Positives (FP): {FP}\")\n",
    "print(f\"False Negatives (FN): {FN}\")\n",
    "print(f\"True Positives (TP): {TP}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08236ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusão\n",
    "TN = 8875\n",
    "FP = 45\n",
    "FN = 1627\n",
    "TP = 75\n",
    "\n",
    "# Taxa de inadimplência (fraude rate) na base de clientes analisados (antes da decisão do modelo)\n",
    "fraud_rate = round((FN + TP) / (TN + FP + FN + TP), 4)\n",
    "\n",
    "# Taxa de aprovação (clientes aprovados pelo modelo)\n",
    "approval_rate = round((TP + FP) / (TN + FP + FN + TP), 4)\n",
    "print(f\"Taxa de inadimplência na base = {fraud_rate * 100}%\")\n",
    "print(f\"Taxa de aprovação pelo modelo = {approval_rate * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc141ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar e imprimir o classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb3be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision, Recall e F1 por Threshold (Random Forest)\n",
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "precisions_rf, recalls_rf, f1s_rf = [], [], []\n",
    "\n",
    "for thr in thresholds:\n",
    "    y_pred_thr = (y_prob_default_1 >= thr).astype(int)\n",
    "    precisions_rf.append(precision_score(y_test, y_pred_thr))\n",
    "    recalls_rf.append(recall_score(y_test, y_pred_thr))\n",
    "    f1s_rf.append(f1_score(y_test, y_pred_thr))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, precisions_rf, label='Precision', marker='o')\n",
    "plt.plot(thresholds, recalls_rf, label='Recall', marker='o')\n",
    "plt.plot(thresholds, f1s_rf, label='F1 Score', marker='o')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision, Recall e F1 Score por Threshold (Random Forest)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d8703e",
   "metadata": {},
   "source": [
    "- O modelo tem alta acurácia geral (0.97%), mas isso é enganoso devido ao forte desbalanceamento da base (muito mais classe 0 do que 1).\n",
    "\n",
    "O recall para a classe positiva é muito baixo (0.99), o que significa que o modelo deixa escapar a grande maioria dos casos positivos (falsos negativos).\n",
    "\n",
    "O modelo é bom para evitar falsos positivos, mas péssimo para capturar positivos — o que pode ser um grande problema se, por exemplo, a classe 1 representa inadimplentes, fraudes ou doenças."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94428e37",
   "metadata": {},
   "source": [
    "#### Feature importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b24732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter importância das features\n",
    "feature_importances = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "})\n",
    "\n",
    "# Ordenar da mais importante para a menos importante\n",
    "feature_importances = feature_importances.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Mostrar top 10\n",
    "print(\"Top 10 Features por importância:\")\n",
    "print(feature_importances.head(10))\n",
    "\n",
    "# Plotar\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importances.head(10), palette='viridis')\n",
    "plt.title('Top 10 Feature Importances - Random Forest')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5cf0d7",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "\n",
    "- income – Renda do cliente, como esperado, é um dos fatores mais determinantes.\n",
    "\n",
    "- Scores externos (ext_score_1, ext_score_4) também aparecem com boa relevância, indicando valor preditivo de dados de crédito de fontes externas.\n",
    "\n",
    "- start_hour – Variável com maior importância. Indica que a hora de início de alguma atividade (talvez transação ou uso do cartão) está fortemente relacionada com a inadimplência ou comportamento-alvo.\n",
    "\n",
    "- payment_min – O valor mínimo de pagamento realizado também é altamente relevante, o que pode indicar dificuldade financeira.\n",
    "\n",
    "- credit_card_initial_line – A linha de crédito inicial concedida influencia o risco de inadimplência.\n",
    "\n",
    "- age – A idade também contribui significativamente, provavelmente por refletir diferentes perfis de risco.\n",
    "\n",
    "- score_date - Data de geração do score tem relevância → pode capturar sazonalidade ou envelhecimento da informação.\n",
    "\n",
    "- score_days - Dias desde a geração do score, confirma a importância da recência da informação. Quanto mais recente, melhor.\n",
    "\n",
    "- score_checks - Número de consultas de score feitas, muitos pedidos de crédito em pouco tempo podem indicar maior risco.\n",
    "\n",
    "- Variáveis agregadas de pagamento e gasto como spends_sum, payment_mean, payment_max e spends_mean aparecem bem ranqueadas, mostrando que o comportamento financeiro geral é importante.\n",
    "\n",
    "- Linhas de crédito (credit_line_max, credit_line_mean, etc.) mostram influência média."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79e40fd",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e4f94c",
   "metadata": {},
   "source": [
    "#### Análise dos Resultados do Modelo Random Forest\n",
    "O modelo Random Forest aplicado ao problema de classificação binária apresentou desempenho excepcional, atingindo praticamente perfeição em todas as métricas de avaliação. Utilizando um conjunto de dados composto por 280.213 registros para treinamento e 70.054 para teste, o modelo foi capaz de generalizar de forma eficaz, mesmo sem a necessidade de ajustes finos ou técnicas avançadas de engenharia de atributos.\n",
    "\n",
    "A matriz de confusão revelou uma performance extremamente precisa, com 58.175 verdadeiros negativos e 11 falsos positivos, além de 11.760 verdadeiros positivos e apenas 108 falsos negativos. Esse resultado demonstra um equilíbrio notável entre sensibilidade e especificidade, além de um controle rígido sobre os erros de classificação.\n",
    "\n",
    "O relatório de classificação reforça essa conclusão, apresentando precisão de 1.00 para ambas as classes, recall de 1.00 para a classe “Não Default” e 0.99 para a classe “Default”, e F1-score de 1.00 e 0.99, respectivamente. A acurácia geral foi de 100%, com médias macro e ponderada igualmente em 1.00 — um indicativo claro de que o modelo conseguiu separar as classes com eficiência quase total.\n",
    "\n",
    "A curva ROC também reflete esse desempenho, com uma AUC perfeita de 1.0000 no teste e uma AUC média de 0.9803 durante validação cruzada. Esses valores confirmam a excelente capacidade do Random Forest de distinguir entre clientes adimplentes e inadimplentes em diferentes limiares de decisão. A curva praticamente encosta no canto superior esquerdo do gráfico, evidenciando sensibilidade e especificidade máximas.\n",
    "\n",
    "Adicionalmente, observou-se que a taxa de inadimplência na base era de aproximadamente 16,94%, e a taxa de aprovação pelo modelo foi de 16,8%. Essa proximidade indica que o modelo está preservando bem a proporção original dos dados, sem ser excessivamente conservador ou permissivo na aprovação.\n",
    "\n",
    "Em resumo, o modelo Random Forest superou todas as expectativas, apresentando desempenho praticamente perfeito na classificação de clientes inadimplentes. Embora resultados tão altos possam levantar suspeitas de sobreajuste em alguns cenários, os dados de validação cruzada e a consistência com as taxas originais da base sugerem que o modelo está bem calibrado e generalizando de forma adequada. Ainda assim, recomenda-se uma análise cuidadosa do desempenho em produção e possível revisão de variáveis importantes para garantir robustez no longo prazo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec134ed1",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fb22ae",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371b87e6",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0979d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprimir todos os formatos (shapes) do train_test_split\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfb0e81",
   "metadata": {},
   "source": [
    "Tamanho dos Dados\n",
    "- Treino: 42.487 amostras com 24 features\n",
    "- Teste: 10.622 amostras com 24 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce79a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar e treinar o modelo\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7862779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo as previsões e avaliando o modelo\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49937b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision, Recall e F1 por Threshold (XGBoost)\n",
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "precisions_xgb, recalls_xgb, f1s_xgb = [], [], []\n",
    "\n",
    "for thr in thresholds:\n",
    "    y_pred_thr = (y_proba >= thr).astype(int)\n",
    "    precisions_xgb.append(precision_score(y_test, y_pred_thr))\n",
    "    recalls_xgb.append(recall_score(y_test, y_pred_thr))\n",
    "    f1s_xgb.append(f1_score(y_test, y_pred_thr))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, precisions_xgb, label='Precision', marker='o')\n",
    "plt.plot(thresholds, recalls_xgb, label='Recall', marker='o')\n",
    "plt.plot(thresholds, f1s_xgb, label='F1 Score', marker='o')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision, Recall e F1 Score por Threshold (XGBoost)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aafd833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar as predições padrão (threshold 0.5)\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "disp.plot(cmap=\"Blues\", values_format='d')  # valores inteiros\n",
    "plt.title(\"Matriz de Confusão - XGBoost (threshold = 0.5)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7263a484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusão\n",
    "TN = 8828\n",
    "FP = 92\n",
    "FN = 1572\n",
    "TP = 130\n",
    "\n",
    "# Taxa de inadimplência (fraude rate) na base de clientes analisados (antes da decisão do modelo)\n",
    "fraud_rate = round((FN + TP) / (TN + FP + FN + TP), 4)\n",
    "\n",
    "# Taxa de aprovação (clientes aprovados pelo modelo)\n",
    "approval_rate = round((TP + FP) / (TN + FP + FN + TP), 4)\n",
    "print(f\"Taxa de inadimplência na base = {fraud_rate * 100}%\")\n",
    "print(f\"Taxa de aprovação pelo modelo = {approval_rate * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb959e5",
   "metadata": {},
   "source": [
    "Matriz de Confusão\n",
    "- Verdadeiros Negativos (TN): 8828\n",
    "- Falsos Positivos (FP): 92\n",
    "- Falsos Negativos (FN): 1572\n",
    "- Verdadeiros Positivos (TP):130\n",
    "\n",
    "O modelo erra 1572 casos positivos como negativos, o que pode ser relevante dependendo do custo da falha. Os falsos positivos são relativamente baixos (92).\n",
    "O modelo é bem conservador ao classificar positivos, porém mantém bom recall (98%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268baa2f",
   "metadata": {},
   "source": [
    "Para as métricas de classificação, temos o seguinte:\n",
    "- Excelente precisão (77%) em ambas as classes.\n",
    "- Recall da classe 1 (positiva) é menor (24%), ou seja, há menos falsos negativos.\n",
    "- F1-score equilibrado, mostrando um bom balanço entre precisão e recall.\n",
    "- A acurácia geral é alta (86%), o que é esperado dado o desequilíbrio (mais exemplos da classe 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a531ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prever no conjunto de teste\n",
    "y_pred_class = model.predict(X_test)                 # classe prevista (0 ou 1)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]     # probabilidade prevista para classe 1 (inadimplência)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d20415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avaliar o modelo com MAE (Erro Absoluto Médio)\n",
    "mae = mean_absolute_error(y_test, y_pred_proba)\n",
    "print(f\"MAE (usando probabilidade): {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc62ddb",
   "metadata": {},
   "source": [
    "MAE = 0.2114, o que indica que a média do erro absoluto entre as probabilidades previstas e as reais é pequena. Isso reforça que o modelo está com desempenho moderado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fbe66d",
   "metadata": {},
   "source": [
    "- A maioria das amostras (classe 0) recebe baixa probabilidade de ser positiva, isso indica que o modelo tem alta confiança para a classe negativa.\n",
    "- As amostras reais da classe 1 (laranja) estão majoritariamente entre 0.2 e 0.7, misturadas com a classe 0, isso sugere que o modelo tem dificuldade em separar claramente a classe positiva.\n",
    "- O modelo é conservador ao atribuir altas probabilidades à classe positiva, isso pode explicar o baixo recall e a alta taxa de falsos negativos vista na matriz de confusão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6239e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular fpr (false positive rate), tpr (true positive rate) e thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "\n",
    "# Plotar a curva ROC\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {roc_auc_score(y_test, y_proba):.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # linha diagonal (classificador aleatório)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39827699",
   "metadata": {},
   "source": [
    "ROC AUC = 0.757, resultado muito bom.\n",
    "\n",
    "- A curva ROC está consistentemente acima da linha aleatória, o que mostra que o modelo tem bom poder de discriminação entre as classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2e78f9",
   "metadata": {},
   "source": [
    "#### Importância das Features - XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6372b049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter importância das features\n",
    "importance = model.feature_importances_\n",
    "\n",
    "# Criar dataframe ordenado\n",
    "feat_importances = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': importance\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(feat_importances.head(20))  # top 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c53a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(feat_importances['feature'], feat_importances['importance'])\n",
    "plt.gca().invert_yaxis()  # Inverter eixo para mostrar maiores no topo\n",
    "plt.xlabel(\"Importância\")\n",
    "plt.title(\"Importância das Features (XGBoost)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea45a7fc",
   "metadata": {},
   "source": [
    "- Quanto mais à direita a barra, maior o impacto da feature na redução do erro durante a construção das árvores.\n",
    "- Esse método (importance_type='gain') foca na qualidade da divisão, não apenas na frequência.\n",
    "- O modelo XGBoost está altamente influenciado por variáveis ligadas a ocupação e scores externos de crédito. Isso faz sentido para problemas de inadimplência, pois esses fatores refletem diretamente a capacidade de pagamento e o risco de crédito."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b2bc74",
   "metadata": {},
   "source": [
    "#### Gráfico SHAP para o modelo XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0a2c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 1: Preparar os dados transformados (sem o target)\n",
    "X_sample = X_test.sample(n=500, random_state=42) \n",
    "\n",
    "# Passo 2: Criar o explainer\n",
    "explainer = shap.Explainer(model)\n",
    "\n",
    "# Passo 3: Calcular os valores SHAP\n",
    "shap_values = explainer(X_sample)\n",
    "shap.summary_plot(shap_values, X_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd73012",
   "metadata": {},
   "source": [
    "- Vermelho = valor alto da feature\n",
    "- Azul = valor baixo da feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556bf7c",
   "metadata": {},
   "source": [
    "Neste grafico observa-se o impacto das features no modelo e assim, temos a certeza de features importantes e que impactam a nossa decisão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af20b430",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be54749",
   "metadata": {},
   "source": [
    "#### Analisando o resultado do modelo XGBoost:\n",
    "\n",
    "O modelo XGBoost aplicado ao problema de classificação binária mostrou resultados bastante promissores, evidenciando boa capacidade de generalização e alta precisão nas previsões.\n",
    "\n",
    "Tamanho dos Dados: O conjunto utilizado é robusto, com 280.213 amostras e 69 features no treinamento, e 70.054 amostras no teste, favorecendo a aprendizagem consistente do modelo.\n",
    "\n",
    "Matriz de Confusão: O modelo classificou corretamente 57.879 verdadeiros negativos e 9.847 verdadeiros positivos, com 307 falsos positivos e 2.021 falsos negativos. Isso indica que, embora o modelo seja conservador na classificação da classe positiva, mantém um recall satisfatório de 83%. A quantidade de falsos negativos pode ser relevante dependendo do impacto do erro no negócio.\n",
    "\n",
    "Métricas de Classificação: A precisão geral foi alta, com média ponderada de 97% para precision e recall. O F1-score equilibrado (0.94 na média macro) demonstra um bom balanço entre precisão e sensibilidade. A acurácia geral do modelo foi de 97%, condizente com o desequilíbrio entre as classes.\n",
    "\n",
    "Curva ROC e AUC: O modelo obteve um AUC de 0.9933, indicando excelente capacidade de separação entre as classes, com alta sensibilidade e especificidade.\n",
    "\n",
    "Erro Absoluto Médio (MAE) das Probabilidades: O MAE de 0.0550 mostra que as probabilidades previstas estão bem calibradas em relação às classes reais, reforçando a confiabilidade do modelo para decisões baseadas em risco.\n",
    "\n",
    "Distribuição das Probabilidades Preditas: O histograma revela que as predições para a classe 0 estão concentradas próximas de zero, e para a classe 1 próximas de um, evidenciando confiança e pouca ambiguidade nas previsões.\n",
    "\n",
    "Considerações Finais:\n",
    "O modelo XGBoost está muito bem ajustado, apresentando alta performance global. É possível considerar ajustes no threshold de decisão para aumentar o recall da classe positiva, caso o custo dos falsos negativos seja elevado. Além disso, a baixa taxa de falsos positivos indica bom controle de erros.\n",
    "\n",
    "Há potencial para aprofundar a análise com ajustes no threshold, interpretação da importância das features e possíveis melhorias no modelo, se desejado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94137b3a",
   "metadata": {},
   "source": [
    "______________________________________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffaa2e2",
   "metadata": {},
   "source": [
    "_________________________________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f042262",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.to_pickle('../data/df_copy_encoded.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050d273a",
   "metadata": {},
   "source": [
    "### Experiments MlFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253b5cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== Configurações ======================\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"CreditScoring_Models\")\n",
    "\n",
    "# ====================== 1. Regressão Logística ======================\n",
    "y_pred_log = pipeline_.predict(X_test)\n",
    "y_proba_log = pipeline_.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc_log = accuracy_score(y_test, y_pred_log)\n",
    "prec_log = precision_score(y_test, y_pred_log)\n",
    "rec_log = recall_score(y_test, y_pred_log)\n",
    "f1_log = f1_score(y_test, y_pred_log)\n",
    "roc_log = roc_auc_score(y_test, y_proba_log)\n",
    "\n",
    "with mlflow.start_run(run_name=\"Logistic Regression\"):\n",
    "    mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_param(\"max_iter\", 1000)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", acc_log)\n",
    "    mlflow.log_metric(\"precision\", prec_log)\n",
    "    mlflow.log_metric(\"recall\", rec_log)\n",
    "    mlflow.log_metric(\"f1_score\", f1_log)\n",
    "    mlflow.log_metric(\"roc_auc\", roc_log)\n",
    "\n",
    "    mlflow.sklearn.log_model(pipeline_, \"model\")\n",
    "\n",
    "# ====================== 2. Random Forest ======================\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "prec_rf = precision_score(y_test, y_pred_rf)\n",
    "rec_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "roc_rf = roc_auc_score(y_test, y_proba_rf)\n",
    "\n",
    "with mlflow.start_run(run_name=\"Random Forest\"):\n",
    "    mlflow.log_param(\"model_type\", \"RandomForestClassifier\")\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"max_depth\", None)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", acc_rf)\n",
    "    mlflow.log_metric(\"precision\", prec_rf)\n",
    "    mlflow.log_metric(\"recall\", rec_rf)\n",
    "    mlflow.log_metric(\"f1_score\", f1_rf)\n",
    "    mlflow.log_metric(\"roc_auc\", roc_rf)\n",
    "\n",
    "    mlflow.sklearn.log_model(rf_model, \"model\")\n",
    "\n",
    "\n",
    "# ====================== 3. XGBoost ======================\n",
    "y_pred_xgb = model.predict(X_test)\n",
    "y_proba_xgb = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "prec_xgb = precision_score(y_test, y_pred_xgb)\n",
    "rec_xgb = recall_score(y_test, y_pred_xgb)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "roc_xgb = roc_auc_score(y_test, y_proba_xgb)\n",
    "\n",
    "with mlflow.start_run(run_name=\"XGBoost\"):\n",
    "    mlflow.log_param(\"model_type\", \"XGBClassifier\")\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"max_depth\", 6)\n",
    "    mlflow.log_param(\"learning_rate\", 0.1)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", acc_xgb)\n",
    "    mlflow.log_metric(\"precision\", prec_xgb)\n",
    "    mlflow.log_metric(\"recall\", rec_xgb)\n",
    "    mlflow.log_metric(\"f1_score\", f1_xgb)\n",
    "    mlflow.log_metric(\"roc_auc\", roc_xgb)\n",
    "\n",
    "    mlflow.sklearn.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e5aa97",
   "metadata": {},
   "source": [
    "#### Comparar modelos no MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd6bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Conectar ao servidor MLflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# 2. Nome do experimento\n",
    "experiment_name = \"CreditScoring_Models\"\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "# 3. Acessar as execuções do experimento\n",
    "client = MlflowClient()\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    order_by=[\"metrics.f1_score DESC\"],\n",
    "    max_results=1000\n",
    ")\n",
    "\n",
    "# 4. Converter resultados em DataFrame\n",
    "df = pd.DataFrame([{\n",
    "    \"run_id\": r.info.run_id,\n",
    "    \"model\": r.data.params.get(\"model_type\"),\n",
    "    \"learning_rate\": r.data.params.get(\"learning_rate\"),\n",
    "    \"max_depth\": r.data.params.get(\"max_depth\"),\n",
    "    \"max_iter\": r.data.params.get(\"max_iter\"),\n",
    "    \"accuracy\": float(r.data.metrics.get(\"accuracy\", 0)),\n",
    "    \"f1_score\": float(r.data.metrics.get(\"f1_score\", 0)),\n",
    "    \"precision\": float(r.data.metrics.get(\"precision\", 0)),\n",
    "    \"recall\": float(r.data.metrics.get(\"recall\", 0)),\n",
    "    \"roc_auc\": float(r.data.metrics.get(\"roc_auc\", 0)),\n",
    "} for r in runs])\n",
    "\n",
    "# 5. Exibir tabela ordenada pelo critério escolhido (ex: f1_score)\n",
    "df_sorted = df.sort_values(by=\"f1_score\", ascending=False)\n",
    "print(df_sorted)\n",
    "\n",
    "# 6. Mostrar o melhor modelo segundo F1 Score\n",
    "best_model = df_sorted.iloc[0]\n",
    "print(\"\\nMelhor modelo:\")\n",
    "print(best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "credit_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
